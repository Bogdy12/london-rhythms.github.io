{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'extract_geodata_file.py',\n",
       " 'extract_tweets.py',\n",
       " 'Real-time tweets(JsonToCsv and Date Cleaning).ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Json to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def json_to_csv(data, output_file):\n",
    "    \n",
    "    file = open(data)\n",
    "    data = json.load(file)\n",
    "    file.close()  \n",
    "    \n",
    "    data_to_file = open(output_file, 'w', encoding=\"utf8\", newline='')\n",
    "    csv_writer = csv.writer(data_to_file, delimiter=\";\")\n",
    "    csv_writer.writerow([\"user_id\", \"screen_name\", \"created_at\", \"timestamp\", \"text_tweet\", \"amount_tweeted\", \"language\", \n",
    "                    \"location\", \"primary_geo\"])\n",
    "    for tweet in data:\n",
    "        user_id = tweet[\"user_id\"]\n",
    "        text_tweet = str(tweet[\"features\"][\"text_tweet\"])\n",
    "        timestamp = tweet[\"features\"][\"timestamp\"]\n",
    "        geo_type = tweet[\"features\"][\"geo_type\"]\n",
    "        screen_name = tweet[\"features\"][\"screen_name\"]\n",
    "        language = tweet[\"features\"][\"language\"]\n",
    "        created_at = tweet[\"features\"][\"created_at\"]\n",
    "        location = tweet[\"features\"][\"location\"]\n",
    "        amount_tweeted = float(tweet[\"features\"][\"tweets\"])\n",
    "        primary_geo = tweet[\"features\"][\"primary_geo\"]\n",
    "        csv_writer.writerow([user_id, screen_name, created_at, timestamp, text_tweet, amount_tweeted, language, \n",
    "                             location, primary_geo])     \n",
    "    data_to_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dates(data, output_file, timestamp_min, timestamp_max):\n",
    "    data = pd.read_csv(data, sep=';')\n",
    "    new_data = data.loc[(data['timestamp'] >= timestamp_min) & (data['timestamp'] < timestamp_max)]\n",
    "    new_data.to_csv(output_file, sep = \";\", index = False, header = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For json_to_csv insert first the geo.json file and secondly the name of the .csv file you want to create. For the clean_dates insert the name of the .csv file you just created and secondly the name of the cleaned .csv file you want to create. The unixtime in milliseconds can be found using the following website: https://currentmillis.com/\n",
    "For example for Sunday 15 April 2018 18:00:00 --> to milliseconds since epoche is 1523811600000 and for Sunday 15 April 2018 23:00:00 is 1523829600000. The 23:00:00 time is is used for the conversion from 23.00.00-06.00.00, then have to take into account to look at the 06.00.01 time to still include 06.00.00 tweets, since the condition set at < timestamp_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# does not work currently since CSV files not included in github \n",
    "#json_to_csv('Sunday15April2018_18002300_geo.json', 'Sunday15April2018_1800_2300.csv')\n",
    "#clean_dates('Sunday15April2018_1800_2300.csv', 'Sunday15April2018_1800_2300_cleaned.csv',\n",
    "#           1523811600000, 1523829600000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
